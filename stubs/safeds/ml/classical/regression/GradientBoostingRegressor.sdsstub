package safeds.ml.classical.regression

from safeds.ml.classical.Bases import GradientBoostingBase
from safeds.ml.classical.regression import Regressor

/**
 * Gradient boosting regression.
 *
 * @param numberOfTrees The number of boosting stages to perform. Gradient boosting is fairly robust to over-fitting so a large
 * number usually results in better performance.
 * @param learningRate The larger the value, the more the model is influenced by each additional tree. If the learning rate is too
 * low, the model might underfit. If the learning rate is too high, the model might overfit.
 */
// TODO Safe-DS does not support multiple inheritance.
class GradientBoostingRegressor(
    @PythonName("number_of_trees") numberOfTrees: Int = 100,
    @PythonName("learning_rate") learningRate: Float = 0.1
) sub Regressor, _GradientBoostingBase
