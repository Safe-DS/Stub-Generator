package safeds.ml.classical.regression

from safeds.ml.classical.regression import Regressor

/**
 * Ada Boost regression.
 *
 * @param learner The learner from which the boosted ensemble is built.
 * @param maxLearnerCount The maximum number of learners at which boosting is terminated. In case of perfect fit, the learning procedure
 * is stopped early. Has to be greater than 0.
 * @param learningRate Weight applied to each regressor at each boosting iteration. A higher learning rate increases the contribution
 * of each regressor. Has to be greater than 0.
 */
class AdaBoostRegressor(
    learner: Regressor? = null,
    @PythonName("max_learner_count") maxLearnerCount: Int = 50,
    @PythonName("learning_rate") learningRate: Float = 1.0
) sub Regressor {
    /**
     * The maximum number of learners in the ensemble.
     */
    @PythonName("max_learner_count") attr maxLearnerCount: Int
    /**
     * The learning rate.
     */
    @PythonName("learning_rate") attr learningRate: Float

    /**
     * The base learner used for training the ensemble.
     */
    attr learner: Regressor?
}
